#!/usr/bin/env python3
"""
Derive query-focused summarization tasks from the existing FinanceBench corpus.

Reuses data/financebench/chunks.json and its FAISS index — no new downloads
or indexing required.  For each of the 40 companies in the FinanceBench
questions, two summarization tasks are generated:
  1. "Summarize the key risk factors for {COMPANY} based on their {YEAR} 10-K"
  2. "What were the major operational highlights for {COMPANY} in FY{YEAR}?"

Reference answers ("silver references") are generated by calling Claude Sonnet
over the existing evidence_text fields from the source QA questions.
A --skip-silver flag skips the LLM step and writes placeholder answers,
which is useful when running without an API key or in dry-run mode.

Outputs:
  data/financebench_sum/questions.json  (reuses data/financebench/ index)

Usage:
    uv run python scripts/derive_financebench_sum.py
    uv run python scripts/derive_financebench_sum.py --limit 10 --skip-silver
"""
from __future__ import annotations

import argparse
import json
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

# ---------------------------------------------------------------------------
# Silver reference generation
# ---------------------------------------------------------------------------

_SILVER_PROMPT = """\
You are a senior financial analyst. Based on the following excerpts from {company}'s \
{year} {doc_type} filing, write a concise professional summary of approximately \
{target_words} words that answers: "{question}"

Only use information present in the excerpts. Be precise and factual.

Excerpts:
{evidence}

Write your summary now:"""


def _generate_silver_reference(
    client,
    model: str,
    company: str,
    year: str,
    doc_type: str,
    question: str,
    evidence: str,
    target_words: int = 200,
) -> str:
    prompt = _SILVER_PROMPT.format(
        company=company,
        year=year,
        doc_type=doc_type,
        question=question,
        evidence=evidence[:6000],   # cap to avoid token overflow
        target_words=target_words,
    )
    response = client.messages.create(
        model=model,
        max_tokens=600,
        temperature=0.0,
        messages=[{"role": "user", "content": prompt}],
    )
    return response.content[0].text.strip()


# ---------------------------------------------------------------------------
# Question templates
# ---------------------------------------------------------------------------

_TEMPLATES = [
    {
        "style": "section",
        "template": "Summarize the key risk factors for {company} based on their FY{year} {doc_type} filing.",
        "suffix": "risks",
        "target_words": 200,
    },
    {
        "style": "query_focused",
        "template": "What were the major operational highlights for {company} in FY{year}?",
        "suffix": "highlights",
        "target_words": 200,
    },
]


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def main() -> None:
    p = argparse.ArgumentParser(
        description="Derive FinanceBench QFS summarization tasks"
    )
    p.add_argument(
        "--fb-questions",
        default="data/financebench/questions.json",
        help="Source FinanceBench questions.json",
    )
    p.add_argument("--output", default="data/financebench_sum")
    p.add_argument(
        "--limit",
        type=int,
        default=None,
        help="Process only the first N companies (dev mode)",
    )
    p.add_argument(
        "--skip-silver",
        action="store_true",
        help="Skip LLM silver-reference generation (writes placeholder answers)",
    )
    p.add_argument(
        "--silver-model",
        default="claude-sonnet-4-6",
        help="Model for silver reference generation (default: claude-sonnet-4-6)",
    )
    args = p.parse_args()

    # ---- Load source questions ----
    fb_path = Path(args.fb_questions)
    if not fb_path.exists():
        print(f"ERROR: {fb_path} not found.")
        print("Run prepare_financebench.py first, or pass --fb-questions <path>.")
        sys.exit(1)

    with open(fb_path) as f:
        fb_questions: list[dict] = json.load(f)

    print(f"Loaded {len(fb_questions)} FinanceBench questions")

    # ---- Group by (company, year, doc_type) — one entry per unique filing ----
    # Use the first question per filing as the evidence source
    seen: dict[tuple, dict] = {}
    for q in fb_questions:
        key = (q.get("company", ""), str(q.get("doc_period", "")), q.get("doc_type", "10-K"))
        if key not in seen:
            seen[key] = q

    filing_groups = list(seen.items())
    if args.limit:
        filing_groups = filing_groups[: args.limit]

    print(f"Unique filings to process: {len(filing_groups)}")

    # ---- Optionally set up Anthropic client for silver references ----
    client = None
    if not args.skip_silver:
        try:
            import anthropic
            from src.arag.config import get_api_key
            client = anthropic.Anthropic(api_key=get_api_key())
            print(f"Silver reference model: {args.silver_model}")
        except Exception as e:
            print(f"WARNING: Could not initialise Anthropic client ({e}). "
                  f"Using --skip-silver mode.")
            args.skip_silver = True

    # ---- Build derived questions ----
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    questions: list[dict] = []
    silver_generated = 0
    silver_skipped   = 0

    for (company, year, doc_type), source_q in filing_groups:
        if not company or not year:
            continue

        doc_type_display = doc_type.upper() if doc_type else "10-K"

        # Collect all evidence text for this filing
        filing_evidence_parts: list[str] = [
            q.get("evidence", "") for q in fb_questions
            if q.get("company") == company
            and str(q.get("doc_period", "")) == year
            and q.get("doc_type", "") == doc_type
            and q.get("evidence")
        ]
        combined_evidence = "\n\n---\n\n".join(filing_evidence_parts[:10])  # cap at 10 passages

        for tmpl in _TEMPLATES:
            question_text = tmpl["template"].format(
                company=company,
                year=year,
                doc_type=doc_type_display,
            )
            question_id = (
                f"fbsum_{company.lower().replace(' ', '_')}"
                f"_{year}_{tmpl['suffix']}"
            )

            # Generate or placeholder silver reference
            if args.skip_silver or not combined_evidence:
                reference = (
                    f"[Silver reference pending — run without --skip-silver to generate. "
                    f"Question: {question_text}]"
                )
                silver_skipped += 1
            else:
                print(f"  Generating silver ref: {question_id} …")
                try:
                    reference = _generate_silver_reference(
                        client=client,
                        model=args.silver_model,
                        company=company,
                        year=year,
                        doc_type=doc_type_display,
                        question=question_text,
                        evidence=combined_evidence,
                        target_words=tmpl["target_words"],
                    )
                    silver_generated += 1
                except Exception as e:
                    print(f"    WARNING: silver ref failed ({e}) — using placeholder")
                    reference = f"[Generation failed: {e}]"
                    silver_skipped += 1

            questions.append({
                "id": question_id,
                "source": "financebench_sum",
                "question": question_text,
                "answer": reference,
                "question_type": "summarization",
                "summarization_style": tmpl["style"],
                "evidence": combined_evidence[:2000],  # store first 2K chars of evidence
                "evidence_relations": [],
                "company": company,
                "doc_period": year,
                "doc_type": doc_type,
            })

    # ---- Write questions.json ----
    questions_file = output_dir / "questions.json"
    with open(questions_file, "w") as f:
        json.dump(questions, f, indent=2)

    print(f"\n{'=' * 55}")
    print(f"FinanceBench QFS derivation complete:")
    print(f"  Filings processed     : {len(filing_groups)}")
    print(f"  Questions generated   : {len(questions)} ({len(_TEMPLATES)} per filing)")
    print(f"  Silver refs generated : {silver_generated}")
    print(f"  Silver refs pending   : {silver_skipped}")
    print(f"  Output                : {questions_file}")
    print(f"{'=' * 55}")

    if silver_skipped > 0:
        print(f"\nTo generate silver references, run without --skip-silver:")
        print(f"  uv run python scripts/derive_financebench_sum.py")

    print(f"\nNext step (reuses existing FinanceBench index):")
    print(f"  uv run python scripts/batch_runner.py \\")
    print(f"    --config configs/financebench_sum.yaml \\")
    print(f"    --questions {questions_file} \\")
    print(f"    --output results/financebench_sum --workers 3 --limit 10")


if __name__ == "__main__":
    main()
